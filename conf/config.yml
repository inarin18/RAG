# meta data
log_level: INFO

# ベクトルストア作成
split_docs:
  use_llm: true
  already_chunked_at_local: true
  chunks_dir_to_restore: chunked_docs
  batch_size: 2500
  separators: 
    - "\n\n"
    - "。"
    - "、"
    - "\n"
  chunk_size: 1000
  chunk_overlap: 200

max_workers: 3

# 各種 LLM モデルの設定
chunker:
  model_provider: anthropic
  model_name: claude-3-5-sonnet-20240620
  temperature: 0
  max_tokens: 8192
conductor:
  model_provider: anthropic
  model_name: claude-3-5-sonnet-20240620
  temperature: 0
  max_tokens: 500
extractor:
  model_provider: anthropic
  model_name: claude-3-5-sonnet-20240620
  temperature: 0
  max_tokens: 500
shortener:
  model_provider: anthropic
  model_name: claude-3-5-sonnet-20240620
  temperature: 0
  max_tokens: 50

# ベクトルストア検索時の設定
top_k: 2
is_ordinal: false
# persist_dir_name: 'vs_cnk_{chunk_size}_ovlp_{chunk_overlap}'
persist_dir_name: vs_llm_2024-10-02-05-31-22

# tool call
tools:
  generate_answer:
    type: function
    function:
      name: generate_answer
      description: "Generate answer and evidence from query"
      parameters: 
        type: object
        properties:
          answer:
            type: string
            description: "Answer to the question"
          evidence:
            type: string
            description: "Evidence for the answer"
        required:
          - answer
          - evidence

  extracting_keywords:
    type: function
    function:
      name: extracting_keywords
      description: "analyze keywords to answer the query correctly"
      parameters: 
        type: object
        properties:
          keywords:
            type: array
            items:
              type: string
            description: "important keywords extracted from the query"
        required:
          - keywords

  shorten_answer:
    type: function
    function:
      name: shorten_answer
      description: "shorten the answer to the query"
      parameters: 
        type: object
        properties:
          shorten_answer:
            type: string
            description: "Summarize the answer to the query"
        required:
          - shorten_answer
  
  for_embedding_chunks:
    type: function
    function:
      name: for_embedding_chunks
      description: "Embedding the chunks"
      parameters: 
        type: object
        properties:
          chunks:
            type: array
            items:
              type: string
            description: "semantic chunks to be embedded"
        required:
          - chunks
